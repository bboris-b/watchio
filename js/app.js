// AI Meeting Tool - Core JavaScript
// Version 2.0 - Advanced AI Integration

// Global Configuration
const CONFIG = {
    providers: {
        free: [
            { name: 'enhanced_template', quality: 8.5, speed: 'instant', always_available: true },
            { name: 'ollama_local', quality: 9, speed: 'fast', local: true },
            { name: 'gemini_free', quality: 8.5, speed: 'fast', limit: 60, endpoint: 'gemini' },
            { name: 'huggingface', quality: 7.5, speed: 'medium', limit: 1000, endpoint: 'hf' }
        ]
    },
    complexity: {
        simple: { threshold: 0, providers: ['enhanced_template', 'ollama_local'] },
        medium: { threshold: 3, providers: ['ollama_local', 'gemini_free', 'enhanced_template'] },
        complex: { threshold: 6, providers: ['ollama_local', 'gemini_free', 'huggingface', 'enhanced_template'] }
    }
};

// Global State
let isRecording = false;
let recognition = null;
let transcript = [];
let currentSpeaker = 'Speaker 1';
let speakerCount = 1;
let activeTab = 'transcript';
let providerManager = null;

// Smart Provider Manager Class
class SmartProviderManager {
    constructor() {
        this.rateLimits = new Map();
        this.failureCount = new Map();
        this.lastReset = new Map();
        this.responseCache = new Map();
    }

    analyzeComplexity(transcript, notes) {
        let score = 0;
        
        // Content length analysis (40% weight)
        const totalWords = transcript.reduce((acc, t) => acc + t.text.split(' ').length, 0);
        if (totalWords > 1000) score += 3;
        else if (totalWords > 500) score += 2;
        else if (totalWords > 100) score += 1;
        
        // Speaker complexity (20% weight)
        const speakers = new Set(transcript.map(t => t.speaker)).size;
        if (speakers > 4) score += 2;
        else if (speakers > 2) score += 1;
        
        // Multi-language (15% weight)
        const languages = new Set(transcript.map(t => t.language)).size;
        if (languages > 1) score += 1;
        
        // Meeting type complexity (15% weight)
        const meetingType = document.getElementById('meetingFormat').value;
        const complexMeetings = ['sales', 'interview', 'training'];
        if (complexMeetings.includes(meetingType)) score += 2;
        
        // Collaborative notes (10% weight)
        if (notes && notes.length > 300) score += 1;
        
        const level = score >= 6 ? 'complex' : score >= 3 ? 'medium' : 'simple';
        
        console.log(`Complexity Analysis: ${level} (score: ${score})`);
        return { score, level };
    }

    async generateSummary(transcript, notes, meetingType) {
        const complexity = this.analyzeComplexity(transcript, notes);
        const availableProviders = this.getAvailableProviders(complexity.level);
        
        console.log(`Available providers for ${complexity.level}:`, availableProviders.map(p => p.name));
        
        this.updateProviderStatus(`Selecting best AI engine...`, 'info');
        
        for (const provider of availableProviders) {
            if (!this.isProviderAvailable(provider)) {
                console.log(`Skipping ${provider.name}: not available`);
                continue;
            }
            
            try {
                console.log(`Trying ${provider.name} (quality: ${provider.quality})...`);
                this.updateProviderStatus(`Using ${provider.name}...`, 'processing');
                
                const result = await this.callProvider(provider, transcript, notes, meetingType, complexity);
                
                this.failureCount.set(provider.name, 0);
                this.updateProviderStatus(`Generated by ${provider.name}`, 'success');
                
                return {
                    summary: result,
                    provider: provider.name,
                    quality: provider.quality,
                    complexity: complexity.level,
                    cost: 'FREE'
                };
                
            } catch (error) {
                console.log(`${provider.name} failed:`, error.message);
                this.handleProviderFailure(provider, error);
                continue;
            }
        }
        
        // Ultimate fallback
        console.log(`All providers failed, using enhanced template`);
        this.updateProviderStatus(`Using enhanced template`, 'fallback');
        
        return {
            summary: this.generateEnhancedTemplate(transcript, notes, meetingType, complexity),
            provider: 'enhanced_template',
            quality: 8.5,
            complexity: complexity.level,
            cost: 'FREE'
        };
    }

    getAvailableProviders(complexityLevel) {
        const providerNames = CONFIG.complexity[complexityLevel].providers;
        return CONFIG.providers.free
            .filter(p => providerNames.includes(p.name))
            .sort((a, b) => b.quality - a.quality);
    }

    isProviderAvailable(provider) {
        if (provider.always_available) return true;
        
        const now = Date.now();
        const failures = this.failureCount.get(provider.name) || 0;
        const lastReset = this.lastReset.get(provider.name) || 0;
        
        // Reset failures every hour
        if (now - lastReset > 3600000) {
            this.failureCount.set(provider.name, 0);
            this.rateLimits.delete(provider.name);
            this.lastReset.set(provider.name, now);
        }
        
        if (failures > 3) return false;
        
        const rateLimitUntil = this.rateLimits.get(provider.name);
        if (rateLimitUntil && now < rateLimitUntil) return false;
        
        return true;
    }

    async callProvider(provider, transcript, notes, meetingType, complexity) {
        const prompt = this.buildPrompt(transcript, notes, meetingType, complexity);
        
        switch (provider.name) {
            case 'ollama_local':
                return await this.callOllama(prompt);
            case 'gemini_free':
                return await this.callGemini(prompt);
            case 'huggingface':
                return await this.callHuggingFace(prompt);
            case 'enhanced_template':
            default:
                return this.generateEnhancedTemplate(transcript, notes, meetingType, complexity);
        }
    }

    async callOllama(prompt) {
        const response = await fetch('http://localhost:11434/api/generate', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: 'llama3.1:8b',
                prompt: prompt,
                stream: false,
                options: { temperature: 0.3, num_predict: 1500 }
            })
        });
        
        if (!response.ok) throw new Error(`Ollama error: ${response.status}`);
        
        const data = await response.json();
        return data.response;
    }

    async callGemini(prompt) {
        // Configuration required: Get your free API key at https://aistudio.google.com/app/apikey
        const API_KEY = 'AIzaSyD3hf0zLaH9nQr5usubL8v75gY8bd_tgfg';
        
        if (API_KEY === 'AIzaSyD3hf0zLaH9nQr5usubL8v75gY8bd_tgfg') {
            throw new Error('Gemini API key not configured. Get yours at https://aistudio.google.com/app/apikey');
        }
        
        const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{ parts: [{ text: prompt }] }],
                generationConfig: { temperature: 0.3, maxOutputTokens: 1500 }
            })
        });
        
        if (!response.ok) {
            if (response.status === 429) {
                this.rateLimits.set('gemini_free', Date.now() + 3600000);
            }
            throw new Error(`Gemini error: ${response.status}`);
        }
        
        const data = await response.json();
        return data.candidates[0].content.parts[0].text;
    }

    async callHuggingFace(prompt) {
        // Configuration required: Get your free token at  
        const HF_TOKEN = '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';
        
        if (HF_TOKEN === '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') {
            throw new Error('HuggingFace token not configured. Get yours at https://huggingface.co/settings/tokens');
        }
        
        const response = await fetch('https://api-inference.huggingface.co/models/microsoft/DialoGPT-large', {
            method: 'POST',
            headers: { 
                'Authorization': `Bearer ${HF_TOKEN}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({ inputs: prompt, parameters: { max_length: 1500 } })
        });
        
        if (!response.ok) {
            if (response.status === 429) {
                this.rateLimits.set('huggingface', Date.now() + 1800000);
            }
            throw new Error(`HuggingFace error: ${response.status}`);
        }
        
        const data = await response.json();
        return data[0].generated_text;
    }

    buildPrompt(transcript, notes, meetingType, complexity) {
        const meetingFormats = {
            general: 'General Meeting',
            sales: 'Sales Call', 
            standup: 'Daily Standup',
            team: 'Team Meeting',
            interview: 'Interview',
            training: 'Training Session'
        };

        const transcriptText = transcript.map(t => 
            `${t.speaker} (${t.timestamp}): ${t.text}`
        ).join('\n');

        return `You are an expert meeting analyst. Create a comprehensive summary of this ${meetingFormats[meetingType] || 'meeting'}.

MEETING TRANSCRIPT:
${transcriptText}

COLLABORATIVE NOTES:
${notes || 'No additional notes provided'}

COMPLEXITY LEVEL: ${complexity.level}
PARTICIPANTS: ${new Set(transcript.map(t => t.speaker)).size} speakers
DURATION: Approximately ${transcript.length} statements

Please provide a structured summary with:
1. KEY HIGHLIGHTS (main topics discussed)
2. ACTION ITEMS (specific tasks and responsibilities)
3. DECISIONS MADE (concrete outcomes)
4. OPEN QUESTIONS (unresolved issues)
5. NEXT STEPS (planned follow-ups)
6. INSIGHTS (patterns, sentiment, participant analysis)

Format your response in clear, scannable sections with bullet points.`;
    }

    generateEnhancedTemplate(transcript, notes, meetingType, complexity) {
        const analysis = this.deepAnalyze(transcript, notes);
        const meetingFormats = {
            general: 'General Meeting',
            sales: 'Sales Call', 
            standup: 'Daily Standup',
            team: 'Team Meeting',
            interview: 'Interview',
            training: 'Training Session'
        };

        return `${meetingFormats[meetingType]} Summary

Meeting Overview:
‚Ä¢ Duration: ${transcript.length} statements recorded
‚Ä¢ Participants: ${analysis.speakers.length} active speakers
‚Ä¢ Languages detected: ${analysis.languages.join(', ')}
‚Ä¢ Complexity level: ${complexity.level}

Key Highlights:
${analysis.keyPoints.map(point => `‚Ä¢ ${point}`).join('\n')}

Action Items:
${analysis.actionItems.map(item => `‚Ä¢ ${item}`).join('\n')}

Decisions Made:
${analysis.decisions.map(decision => `‚Ä¢ ${decision}`).join('\n')}

Questions Raised:
${analysis.questions.map(q => `‚Ä¢ ${q}`).join('\n')}

Participant Analysis:
${analysis.speakers.map(speaker => 
    `‚Ä¢ ${speaker.name}: ${speaker.contributions} contributions (${speaker.engagement})`
).join('\n')}

Meeting Insights:
‚Ä¢ Most active speaker: ${analysis.mostActive}
‚Ä¢ Sentiment: ${analysis.sentiment}
‚Ä¢ Meeting flow: ${analysis.flow}
‚Ä¢ Key topics: ${analysis.topics.join(', ')}

Next Steps:
${analysis.nextSteps.map(step => `‚Ä¢ ${step}`).join('\n')}

Collaborative Notes Integration:
${notes ? notes.split('\n').map(note => note.trim() ? `‚Ä¢ ${note.trim()}` : '').filter(Boolean).join('\n') : '‚Ä¢ No additional notes provided'}

Summary generated using enhanced AI template - Quality level: ${8.5}/10`;
    }

    deepAnalyze(transcript, notes) {
        const text = transcript.map(t => t.text).join(' ').toLowerCase();
        const speakers = [...new Set(transcript.map(t => t.speaker))];
        
        return {
            speakers: speakers.map(speaker => ({
                name: speaker,
                contributions: transcript.filter(t => t.speaker === speaker).length,
                engagement: this.calculateEngagement(transcript, speaker)
            })),
            languages: [...new Set(transcript.map(t => t.language))],
            keyPoints: this.extractKeyPoints(text, notes),
            actionItems: this.extractActionItems(text, notes),
            decisions: this.extractDecisions(text),
            questions: this.extractQuestions(transcript),
            mostActive: this.getMostActiveSpeaker(transcript),
            sentiment: this.analyzeSentiment(text),
            flow: this.analyzeMeetingFlow(transcript),
            topics: this.extractTopics(text),
            nextSteps: this.extractNextSteps(text, notes)
        };
    }

    calculateEngagement(transcript, speaker) {
        const speakerEntries = transcript.filter(t => t.speaker === speaker);
        const avgLength = speakerEntries.reduce((acc, t) => acc + t.text.length, 0) / speakerEntries.length;
        
        if (avgLength > 100) return 'High engagement';
        if (avgLength > 50) return 'Medium engagement';
        return 'Low engagement';
    }

    extractKeyPoints(text, notes) {
        const keyPatterns = [
            /(?:important|key|main|primary|significant|crucial)\s+(.{10,100})/gi,
            /(?:focus on|priority|emphasis on)\s+(.{10,80})/gi,
            /(?:the main|primary concern|key issue)\s+(.{10,80})/gi
        ];
        
        const points = [];
        keyPatterns.forEach(pattern => {
            const matches = [...text.matchAll(pattern)];
            matches.forEach(match => points.push(match[1].trim()));
        });
        
        // Add points from notes
        if (notes) {
            const noteLines = notes.split('\n').filter(line => line.includes('‚Ä¢') || line.includes('üí°'));
            points.push(...noteLines.map(line => line.replace(/[‚Ä¢üí°]/g, '').trim()).filter(Boolean));
        }
        
        return points.slice(0, 5).length > 0 ? points.slice(0, 5) : ['Meeting discussion points captured in transcript'];
    }

    extractActionItems(text, notes) {
        const actionPatterns = [
            /(?:action|todo|task|follow.?up|next step|need to|should|must|will)\s+(.{10,100})/gi,
            /(?:assign|responsible|owner|@\w+)\s+(.{10,80})/gi,
            /by\s+(?:tomorrow|next week|friday|\d+\/\d+)\s*:?\s*(.{10,80})/gi
        ];
        
        const actions = [];
        const allText = text + ' ' + (notes || '');
        
        actionPatterns.forEach(pattern => {
            const matches = [...allText.matchAll(pattern)];
            matches.forEach(match => actions.push(match[1].trim()));
        });
        
        return actions.slice(0, 5).length > 0 ? actions.slice(0, 5) : ['Follow up on meeting discussion points'];
    }

    extractDecisions(text) {
        const decisionPatterns = [
            /(?:decided|decision|agree|approved|confirmed|final|settled)\s+(.{10,100})/gi,
            /(?:we will|going with|choosing|selected)\s+(.{10,80})/gi
        ];
        
        const decisions = [];
        decisionPatterns.forEach(pattern => {
            const matches = [...text.matchAll(pattern)];
            matches.forEach(match => decisions.push(match[1].trim()));
        });
        
        return decisions.slice(0, 3).length > 0 ? decisions.slice(0, 3) : ['Decision points to be confirmed'];
    }

    extractQuestions(transcript) {
        const questions = transcript
            .filter(t => t.text.includes('?'))
            .map(t => t.text.trim())
            .slice(0, 3);
        
        return questions.length > 0 ? questions : ['Questions to be addressed in follow-up'];
    }

    getMostActiveSpeaker(transcript) {
        if (transcript.length === 0) return 'N/A';
        
        const speakerCounts = {};
        transcript.forEach(t => {
            speakerCounts[t.speaker] = (speakerCounts[t.speaker] || 0) + 1;
        });
        
        return Object.keys(speakerCounts).reduce((a, b) => 
            speakerCounts[a] > speakerCounts[b] ? a : b
        );
    }

    analyzeSentiment(text) {
        const positiveWords = ['great', 'good', 'excellent', 'positive', 'agree', 'success', 'perfect'];
        const negativeWords = ['issue', 'problem', 'concern', 'difficult', 'challenging', 'wrong'];
        
        const words = text.split(' ');
        const positive = words.filter(word => positiveWords.some(pw => word.includes(pw))).length;
        const negative = words.filter(word => negativeWords.some(nw => word.includes(nw))).length;
        
        if (positive > negative) return 'Positive';
        if (negative > positive) return 'Cautious';
        return 'Neutral';
    }

    analyzeMeetingFlow(transcript) {
        if (transcript.length < 5) return 'Brief discussion';
        if (transcript.length < 15) return 'Focused conversation';
        if (transcript.length < 30) return 'Detailed discussion';
        return 'Comprehensive meeting';
    }

    extractTopics(text) {
        const commonTopics = [
            'project', 'timeline', 'budget', 'team', 'client', 'development', 
            'strategy', 'planning', 'review', 'goals', 'targets', 'deadlines'
        ];
        
        const foundTopics = commonTopics.filter(topic => 
            text.toLowerCase().includes(topic)
        );
        
        return foundTopics.slice(0, 4).length > 0 ? foundTopics.slice(0, 4) : ['General discussion'];
    }

    extractNextSteps(text, notes) {
        const nextStepPatterns = [
            /(?:next step|next week|follow up|upcoming|planned|schedule)\s+(.{10,80})/gi,
            /(?:will|shall|going to|planning to)\s+(.{10,80})/gi
        ];
        
        const steps = [];
        const allText = text + ' ' + (notes || '');
        
        nextStepPatterns.forEach(pattern => {
            const matches = [...allText.matchAll(pattern)];
            matches.forEach(match => steps.push(match[1].trim()));
        });
        
        return steps.slice(0, 4).length > 0 ? steps.slice(0, 4) : ['Schedule follow-up meeting', 'Review meeting outcomes'];
    }

    handleProviderFailure(provider, error) {
        const failures = this.failureCount.get(provider.name) || 0;
        this.failureCount.set(provider.name, failures + 1);
        
        if (error.message.includes('rate limit') || error.message.includes('429')) {
            const cooldown = provider.limit === 60 ? 3600000 : 1800000; // 1h for Gemini, 30min for others
            this.rateLimits.set(provider.name, Date.now() + cooldown);
        }
    }

    updateProviderStatus(message, type = 'info') {
        const statusEl = document.getElementById('providerStatus');
        const iconEl = document.getElementById('providerIcon');
        const nameEl = document.getElementById('providerName');
        const detailsEl = document.getElementById('providerDetails');
        
        if (statusEl) {
            statusEl.classList.remove('hidden');
            
            const icons = {
                info: 'ü§ñ',
                processing: '‚ö°',
                success: '‚úÖ',
                fallback: 'üõ°Ô∏è',
                error: '‚ùå'
            };
            
            if (iconEl) iconEl.textContent = icons[type] || 'ü§ñ';
            if (nameEl) nameEl.textContent = message.split(' ')[1] || 'AI Engine';
            if (detailsEl) detailsEl.textContent = message;
        }
    }
}

// Speech Recognition Setup
function initializeSpeechRecognition() {
    console.log('Checking Speech Recognition support...');
    
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new SpeechRecognition();
        
        console.log('Speech Recognition available');
        
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = document.getElementById('language').value;
        
        recognition.onstart = function() {
            console.log('Speech Recognition STARTED');
            showMessage('Recording started successfully!', 'success');
        };
        
        recognition.onresult = function(event) {
            let finalTranscript = '';
            
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const transcript = event.results[i][0].transcript;
                
                if (event.results[i].isFinal) {
                    finalTranscript += transcript;
                }
            }
            
            if (finalTranscript.trim()) {
                console.log('Adding to transcript:', finalTranscript);
                addTranscriptEntry(finalTranscript.trim());
            }
        };
        
        recognition.onerror = function(event) {
            console.error('Speech recognition error:', event.error);
            
            let errorMsg = '';
            switch(event.error) {
                case 'not-allowed':
                    errorMsg = 'Microphone permission denied. Please allow microphone access and try again.';
                    break;
                case 'no-speech':
                    errorMsg = 'No speech detected. Please speak more clearly.';
                    break;
                case 'audio-capture':
                    errorMsg = 'Cannot capture audio. Please check your microphone.';
                    break;
                case 'network':
                    errorMsg = 'Network error. Please check your internet connection.';
                    break;
                default:
                    errorMsg = `Error: ${event.error}`;
            }
            
            showMessage(errorMsg, 'error');
        };
        
        recognition.onend = function() {
            console.log('Speech Recognition ENDED');
            
            if (isRecording) {
                console.log('Restarting recognition...');
                setTimeout(() => {
                    try {
                        recognition.start();
                    } catch (e) {
                        console.error('Restart error:', e);
                    }
                }, 100);
            }
        };
        
    } else {
        console.error('Speech Recognition NOT supported');
        showMessage('Speech Recognition not supported. Please use Chrome, Edge, or Safari.', 'error');
    }
}

// Core Functions
function setupEventListeners() {
    document.getElementById('recordBtn').addEventListener('click', toggleRecording);
    document.getElementById('addSpeaker').addEventListener('click', addSpeaker);
    document.getElementById('language').addEventListener('change', changeLanguage);
}

async function toggleRecording() {
    console.log('Toggle recording clicked');
    
    if (!recognition) {
        showMessage('Speech Recognition not available. Please use a supported browser.', 'error');
        return;
    }

    const btn = document.getElementById('recordBtn');
    const status = document.getElementById('recordingStatus');

    try {
        if (!isRecording) {
            console.log('Requesting microphone permission...');
            
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            console.log('Microphone OK');
            stream.getTracks().forEach(track => track.stop());
            
            recognition.lang = document.getElementById('language').value;
            recognition.start();
            
            isRecording = true;
            btn.innerHTML = 'üõë Stop Recording';
            btn.className = 'btn btn-danger';
            status.style.display = 'flex';
            
            console.log('Recording started!');
            
        } else {
            console.log('Stopping recording...');
            recognition.stop();
            isRecording = false;
            btn.innerHTML = 'üé§ Start Recording';
            btn.className = 'btn btn-primary';
            status.style.display = 'none';
            
            if (transcript.length > 0) {
                showMessage('Recording completed! Generate AI summary now.', 'success');
            }
            
            console.log('Recording stopped!');
        }
    } catch (error) {
        console.error('Recording error:', error);
        
        let errorMsg = 'Microphone error: ';
        if (error.name === 'NotAllowedError') {
            errorMsg += 'Permission denied. Please allow microphone access in your browser settings.';
        } else if (error.name === 'NotFoundError') {
            errorMsg += 'Microphone not found. Please check your audio devices.';
        } else {
            errorMsg += error.message;
        }
        
        showMessage(errorMsg, 'error');
    }
}

function addTranscriptEntry(text) {
    const now = new Date();
    const timeString = now.toLocaleTimeString('it-IT', { 
        hour: '2-digit', 
        minute: '2-digit',
        second: '2-digit'
    });
    
    const entry = {
        id: Date.now(),
        speaker: currentSpeaker,
        text: text,
        timestamp: timeString,
        language: detectLanguage(text)
    };
    
    transcript.push(entry);
    updateTranscriptUI();
    
    // Smart speaker cycling
    setTimeout(() => {
        if (Math.random() > 0.75) {
            cycleSpeaker();
        }
    }, 1000);
}

function detectLanguage(text) {
    const patterns = {
        IT: ['che', 'del', 'una', 'con', 'per', 'come', 'questo', 'sono', 'abbiamo', 'deve'],
        EN: ['the', 'and', 'that', 'have', 'for', 'not', 'with', 'you', 'this', 'but'],
        ES: ['que', 'del', 'una', 'con', 'por', 'como', 'este', 'son', 'tenemos', 'debe'],
        FR: ['que', 'des', 'une', 'avec', 'pour', 'comme', 'cette', 'sont', 'avons', 'doit'],
        DE: ['das', 'und', 'eine', 'mit', 'f√ºr', 'wie', 'diese', 'sind', 'haben', 'muss']
    };
    
    const words = text.toLowerCase().split(' ');
    const scores = {};
    
    Object.keys(patterns).forEach(lang => {
        scores[lang] = words.filter(word => patterns[lang].includes(word)).length;
    });
    
    return Object.keys(scores).reduce((a, b) => scores[a] > scores[b] ? a : b) || 'EN';
}

function updateTranscriptUI() {
    const container = document.getElementById('transcriptList');
    const empty = document.getElementById('transcriptEmpty');
    const count = document.getElementById('transcriptCount');
    
    if (transcript.length === 0) {
        container.classList.add('hidden');
        empty.classList.remove('hidden');
    } else {
        container.classList.remove('hidden');
        empty.classList.add('hidden');
        
        container.innerHTML = transcript.map(entry => `
            <div class="transcript-item">
                <div class="speaker-avatar" style="background: ${getSpeakerColor(entry.speaker)}">
                    ${entry.speaker.slice(-1)}
                </div>
                <div class="transcript-content">
                    <div class="transcript-meta">
                        <span class="speaker-name">${entry.speaker}</span>
                        <span class="timestamp">${entry.timestamp}</span>
                        <span class="language-tag">${entry.language}</span>
                    </div>
                    <p class="transcript-text">${entry.text}</p>
                </div>
            </div>
        `).join('');
        
        container.scrollTop = container.scrollHeight;
    }
    
    count.textContent = transcript.length;
}

function getSpeakerColor(speaker) {
    const colors = [
        'linear-gradient(135deg, #3b82f6, #1d4ed8)',
        'linear-gradient(135deg, #10b981, #059669)', 
        'linear-gradient(135deg, #f59e0b, #d97706)',
        'linear-gradient(135deg, #ef4444, #dc2626)',
        'linear-gradient(135deg, #8b5cf6, #7c3aed)',
        'linear-gradient(135deg, #06b6d4, #0891b2)'
    ];
    
    const speakerNumber = parseInt(speaker.split(' ')[1]) || 1;
    return colors[(speakerNumber - 1) % colors.length];
}

function addSpeaker() {
    speakerCount++;
    cycleSpeaker();
}

function cycleSpeaker() {
    const speakerNumber = (parseInt(currentSpeaker.split(' ')[1]) % speakerCount) + 1;
    currentSpeaker = `Speaker ${speakerNumber}`;
    document.getElementById('currentSpeaker').textContent = currentSpeaker;
}

function changeLanguage() {
    const newLang = document.getElementById('language').value;
    if (recognition && isRecording) {
        recognition.stop();
        setTimeout(() => {
            recognition.lang = newLang;
            recognition.start();
        }, 100);
    }
}

function switchTab(tabName) {
    document.querySelectorAll('.tab-btn').forEach(btn => {
        btn.classList.remove('active');
        btn.setAttribute('aria-selected', 'false');
    });
    document.getElementById(`tab-${tabName}`).classList.add('active');
    document.getElementById(`tab-${tabName}`).setAttribute('aria-selected', 'true');
    
    document.querySelectorAll('.tab-content').forEach(tab => {
        tab.classList.add('hidden');
    });
    document.getElementById(`content-${tabName}`).classList.remove('hidden');
    
    activeTab = tabName;
}

function copyTranscript() {
    if (transcript.length === 0) {
        showMessage('No transcript to copy', 'error');
        return;
    }
    
    const text = transcript.map(t => `${t.speaker} (${t.timestamp}): ${t.text}`).join('\n');
    navigator.clipboard.writeText(text).then(() => {
        showMessage('Transcript copied to clipboard!', 'success');
    }).catch(() => {
        showMessage('Failed to copy transcript', 'error');
    });
}

function exportTranscript() {
    if (transcript.length === 0) {
        showMessage('No transcript to export', 'error');
        return;
    }
    
    const exportData = {
        metadata: {
            meetingFormat: document.getElementById('meetingFormat').value,
            language: document.getElementById('language').value,
            timestamp: new Date().toISOString(),
            duration: transcript.length,
            speakers: speakerCount,
            version: '2.0'
        },
        transcript: transcript,
        notes: document.getElementById('notesText').value,
        summary: document.getElementById('summaryText').textContent,
        analytics: {
            totalWords: transcript.reduce((acc, t) => acc + t.text.split(' ').length, 0),
            languages: [...new Set(transcript.map(t => t.language))],
            mostActiveSpeaker: getMostActiveSpeaker(),
            averageStatementLength: transcript.reduce((acc, t) => acc + t.text.length, 0) / transcript.length
        }
    };
    
    const blob = new Blob([JSON.stringify(exportData, null, 2)], { type: 'application/json' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `ai-meeting-${Date.now()}.json`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
    
    showMessage('Meeting data exported successfully!', 'success');
}

async function generateSummary() {
    if (transcript.length === 0) {
        showMessage('No transcript available for summary generation', 'error');
        return;
    }
    
    const loading = document.getElementById('summaryLoading');
    const empty = document.getElementById('summaryEmpty');
    const content = document.getElementById('summaryContent');
    
    loading.classList.remove('hidden');
    empty.classList.add('hidden');
    content.classList.add('hidden');
    
    switchTab('summary');
    
    try {
        const meetingType = document.getElementById('meetingFormat').value;
        const notes = document.getElementById('notesText').value;
        
        console.log('Starting AI summary generation...');
        const result = await providerManager.generateSummary(transcript, notes, meetingType);
        
        const meetingFormats = {
            general: 'General Meeting',
            sales: 'Sales Call', 
            standup: 'Daily Standup',
            team: 'Team Meeting',
            interview: 'Interview',
            training: 'Training Session'
        };
        
        document.getElementById('summaryFormat').textContent = meetingFormats[meetingType];
        document.getElementById('summaryText').textContent = result.summary;
        
        loading.classList.add('hidden');
        content.classList.remove('hidden');
        
        showMessage(`Summary generated using ${result.provider} (Quality: ${result.quality}/10)`, 'success');
        
    } catch (error) {
        console.error('Summary generation failed:', error);
        loading.classList.add('hidden');
        empty.classList.remove('hidden');
        showMessage('Failed to generate summary. Please try again.', 'error');
    }
}

function clearAll() {
    if (transcript.length === 0 && !document.getElementById('notesText').value) {
        showMessage('Nothing to clear', 'info');
        return;
    }
    
    if (confirm('Are you sure you want to clear all data? This action cannot be undone.')) {
        transcript = [];
        currentSpeaker = 'Speaker 1';
        speakerCount = 1;
        
        document.getElementById('notesText').value = '';
        document.getElementById('summaryText').textContent = '';
        document.getElementById('currentSpeaker').textContent = currentSpeaker;
        
        updateTranscriptUI();
        
        document.getElementById('summaryContent').classList.add('hidden');
        document.getElementById('summaryEmpty').classList.remove('hidden');
        document.getElementById('providerStatus').classList.add('hidden');
        
        switchTab('transcript');
        showMessage('All data cleared successfully', 'success');
    }
}

function getMostActiveSpeaker() {
    if (transcript.length === 0) return 'N/A';
    
    const speakerCounts = {};
    transcript.forEach(t => {
        speakerCounts[t.speaker] = (speakerCounts[t.speaker] || 0) + 1;
    });
    
    return Object.keys(speakerCounts).reduce((a, b) => 
        speakerCounts[a] > speakerCounts[b] ? a : b
    );
}

function showMessage(message, type = 'info') {
    const existingMessages = document.querySelectorAll('.message');
    existingMessages.forEach(msg => msg.remove());
    
    const messageEl = document.createElement('div');
    messageEl.className = `message ${type}`;
    messageEl.innerHTML = `
        <span>${type === 'success' ? '‚úÖ' : type === 'error' ? '‚ùå' : '‚ÑπÔ∏è'}</span>
        <span>${message}</span>
    `;
    
    const container = document.querySelector('.container');
    container.insertBefore(messageEl, container.firstChild);
    
    setTimeout(() => {
        if (messageEl.parentNode) {
            messageEl.remove();
        }
    }, 5000);
}

// Initialize App
document.addEventListener('DOMContentLoaded', function() {
    console.log('Initializing AI Meeting Tool...');
    
    providerManager = new SmartProviderManager();
    initializeSpeechRecognition();
    setupEventListeners();
    checkOllamaAvailability();
    
    showMessage('AI Meeting Tool ready! Click "Start Recording" to begin.', 'success');
    
    console.log('Initialization complete!');
});

async function checkOllamaAvailability() {
    try {
        const response = await fetch('http://localhost:11434/api/tags', {
            method: 'GET'
        });
        
        if (response.ok) {
            console.log('Ollama detected locally');
            providerManager.updateProviderStatus('Local AI ready (Ollama)', 'success');
        } else {
            console.log('Ollama not available, using cloud providers');
        }
    } catch (error) {
        console.log('Ollama not detected, using cloud providers');
    }
}

// PWA Service Worker Registration
if ('serviceWorker' in navigator) {
    window.addEventListener('load', function() {
        const swCode = `
            const CACHE_NAME = 'ai-meeting-tool-v1';
            const urlsToCache = ['/'];
            
            self.addEventListener('install', function(event) {
                event.waitUntil(
                    caches.open(CACHE_NAME)
                        .then(function(cache) {
                            return cache.addAll(urlsToCache);
                        })
                );
            });
            
            self.addEventListener('fetch', function(event) {
                event.respondWith(
                    caches.match(event.request)
                        .then(function(response) {
                            if (response) {
                                return response;
                            }
                            return fetch(event.request);
                        })
                );
            });
        `;
        
        const blob = new Blob([swCode], { type: 'application/javascript' });
        const swUrl = URL.createObjectURL(blob);
        
        navigator.serviceWorker.register(swUrl)
            .then(function(registration) {
                console.log('Service Worker registered');
            })
            .catch(function(error) {
                console.log('Service Worker registration failed:', error);
            });
    });
}

// Keyboard Shortcuts
document.addEventListener('keydown', function(event) {
    if ((event.ctrlKey || event.metaKey) && event.key === 'r') {
        event.preventDefault();
        toggleRecording();
    }
    
    if ((event.ctrlKey || event.metaKey) && event.key === 's') {
        event.preventDefault();
        generateSummary();
    }
    
    if ((event.ctrlKey || event.metaKey) && event.key === 'e') {
        event.preventDefault();
        exportTranscript();
    }
    
    if (event.key >= '1' && event.key <= '3' && !event.ctrlKey && !event.metaKey && !event.altKey) {
        const tabs = ['transcript', 'notes', 'summary'];
        const tabIndex = parseInt(event.key) - 1;
        if (tabIndex < tabs.length) {
            event.preventDefault();
            switchTab(tabs[tabIndex]);
        }
    }
});

// Auto-save to localStorage
function autoSave() {
    if (transcript.length > 0) {
        const saveData = {
            transcript,
            notes: document.getElementById('notesText').value,
            timestamp: Date.now()
        };
        
        try {
            localStorage.setItem('ai-meeting-autosave', JSON.stringify(saveData));
            console.log('Auto-saved meeting data');
        } catch (error) {
            console.log('Auto-save failed:', error);
        }
    }
}

setInterval(autoSave, 30000);

function loadAutoSave() {
    try {
        const saved = localStorage.getItem('ai-meeting-autosave');
        if (saved) {
            const data = JSON.parse(saved);
            const timeDiff = Date.now() - data.timestamp;
            
            if (timeDiff < 3600000 && data.transcript.length > 0) {
                if (confirm('Found auto-saved meeting data. Would you like to restore it?')) {
                    transcript = data.transcript;
                    document.getElementById('notesText').value = data.notes || '';
                    updateTranscriptUI();
                    showMessage('Auto-saved data restored', 'success');
                }
            }
        }
    } catch (error) {
        console.log('No auto-save data found');
    }
}

setTimeout(loadAutoSave, 1000);

// Test interface for development
window.AITestInterface = {
    addTestTranscript: (text, speaker = null) => {
        addTranscriptEntry(text);
        if (speaker) currentSpeaker = speaker;
    },
    generateTestSummary: () => generateSummary(),
    clearTestData: () => clearAll(),
    getTranscript: () => transcript,
    getProviderManager: () => providerManager
};

console.log('AI Meeting Tool loaded successfully!');
console.log('Keyboard shortcuts: Ctrl+R (record), Ctrl+S (summary), Ctrl+E (export), 1/2/3 (tabs)');
console.log('Test interface available at window.AITestInterface');